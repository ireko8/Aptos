{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import random\n",
    "import logging\n",
    "from pprint import pformat\n",
    "from datetime import datetime\n",
    "from contextlib import contextmanager\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "from math import cos, pi\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import sklearn.metrics\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from albumentations import CLAHE, HorizontalFlip, Compose, HueSaturationValue, RandomBrightness, RandomContrast, Normalize, Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    def __init__(self, home=True):\n",
    "        self.seed = 71\n",
    "        self.batch_size = 16\n",
    "        self.accum_time = 4\n",
    "        self.train_dir = '../input/train'\n",
    "        self.train_csv = '../input/train.csv'\n",
    "        self.test_dir = '../input/test'\n",
    "        self.test_csv = '../input/sample_submission.csv'\n",
    "        self.device_name = 'cuda:0'\n",
    "        self.image_size = 256\n",
    "        self.n_splits = 5\n",
    "        self.fold = 0\n",
    "        self.num_epoch = 320\n",
    "        self.lr_step_epoch = 64\n",
    "        self.alpha = 1\n",
    "        self.init_lr = 1e-3\n",
    "        self.eta_min = 1e-6\n",
    "        self.num_workers = 16 if home else 4\n",
    "        self.classes_num = 5\n",
    "    \n",
    "conf = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def now():\n",
    "    return datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    \n",
    "def load_csv(path):\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "\n",
    "def count_parameter(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    lr = list()\n",
    "    for param_group in optimizer.param_groups:\n",
    "        lr.append(param_group['lr'])\n",
    "    if len(lr) == 1:\n",
    "        return lr[0]\n",
    "    else:\n",
    "        return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for kernel\n",
    "def setup(exp_name, config):\n",
    "    \"\"\"init experiment (directory setup etc...)\"\"\"\n",
    "\n",
    "    result_dir = Path(f'../result/{exp_name}/')\n",
    "    result_dir.mkdir(parents=True)\n",
    "\n",
    "    set_seed(config.seed)\n",
    "\n",
    "    device = torch.device(config.device_name)\n",
    "\n",
    "    log = Logger(exp_name, result_dir / 'exp.log')\n",
    "\n",
    "    log.info(\"configuration is following...\")\n",
    "    log.info(pformat(config.__dict__))\n",
    "\n",
    "    return device, log, result_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger:\n",
    "    \"\"\"Logging Uitlity Class for monitoring and debugging\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 name,\n",
    "                 log_fname,\n",
    "                 log_level=logging.INFO,\n",
    "                 custom_log_handler=None):\n",
    "\n",
    "        self.name = name\n",
    "        self.logger = logging.getLogger(name)\n",
    "        self.logger.setLevel(log_level)\n",
    "        ch = logging.FileHandler(log_fname)\n",
    "        self.logger.addHandler(ch)\n",
    "        self.logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "        if custom_log_handler:\n",
    "            if isinstance(custom_log_handler, list):\n",
    "                for handler in custom_log_handler:\n",
    "                    self.logger.addHandler(handler)\n",
    "            else:\n",
    "                self.logger.addHandler(handler)\n",
    "\n",
    "    def kiritori(self):\n",
    "        self.logger.info('-'*80)\n",
    "\n",
    "    def double_kiritori(self):\n",
    "        self.logger.info('='*80)\n",
    "\n",
    "    def space(self):\n",
    "        self.logger.info('\\n')\n",
    "\n",
    "    @contextmanager\n",
    "    def interval_timer(self, name):\n",
    "        start_time = datetime.now()\n",
    "        self.logger.info(\"\\n\")\n",
    "        self.logger.info(f\"Execution {name} start at {start_time}\")\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            end_time = datetime.now()\n",
    "            td = end_time - start_time\n",
    "            self.logger.info(f\"Execution {name} end at {end_time}\")\n",
    "            self.logger.info(f\"Execution Time : {td}\")\n",
    "            self.logger.info(\"\\n\")\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        \"\"\"\n",
    "        for calling logging class attribute\n",
    "        if you call attributes of other class, raise AttributeError\n",
    "        \"\"\"\n",
    "        # self.logger.info(f\"{datetime.now()}\")\n",
    "        return getattr(self.logger, attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_transform = Compose([\n",
    "    Resize(conf.image_size, conf.image_size),\n",
    "    Normalize(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_num(target):\n",
    "    labels = np.zeros(conf.classes_num)\n",
    "#     for t in range(target+1):\n",
    "#         labels[t] = 1\n",
    "    labels[target] = 1\n",
    "    return labels.astype(np.float32)\n",
    "\n",
    "\n",
    "class APTOSDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 root_dir,\n",
    "                 data_csv,\n",
    "                 augment=None,\n",
    "                 test=False,\n",
    "                mixup=False):\n",
    "        super().__init__()\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.data_csv = data_csv\n",
    "        self.augment = augment\n",
    "        self.test = test\n",
    "        self.mixup = mixup\n",
    "        \n",
    "    def do_mixup(self, img, label, alpha=1.):\n",
    "        index = np.random.randint(0,len(self.data_csv))\n",
    "        row = self.data_csv.loc[index]\n",
    "        fname = f\"{row.id_code}.png\"\n",
    "        fpath = self.root_dir / fname\n",
    "        img2 = np.array(Image.open(fpath))\n",
    "        if self.augment:\n",
    "            img2 = self.augment(image=img2)['image']\n",
    "            img2 = np.moveaxis(img2, -1, 0)\n",
    "        \n",
    "        label2 = row.diagnosis\n",
    "        label2 = convert_num(label2)\n",
    "        \n",
    "        rate = np.random.beta(alpha,alpha)\n",
    "        img = img*rate + img2*(1-rate)\n",
    "        label = label*rate + label2*(1-rate)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_csv)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = dict()\n",
    "        row = self.data_csv.loc[index]\n",
    "        fname = f\"{row.id_code}.png\"\n",
    "        fpath = self.root_dir / fname\n",
    "        image = np.array(Image.open(fpath))\n",
    "        \n",
    "        if self.augment:\n",
    "            image = self.augment(image=image)['image']\n",
    "            image = np.moveaxis(image, -1, 0)\n",
    "        \n",
    "        if self.test != \"test\":\n",
    "            label = convert_num(row.diagnosis)\n",
    "            if self.mixup and np.random.random()<0.5:\n",
    "                image, label = self.do_mixup(image, label)\n",
    "            sample['label'] = label\n",
    "\n",
    "        sample['data'] = np.array(image)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_init_fn(worker_id):                                                          \n",
    "    np.random.seed(conf.seed + worker_id)\n",
    "\n",
    "def make_loader(df,\n",
    "                root_dir,\n",
    "                batch_size=conf.batch_size,\n",
    "                shuffle=True,\n",
    "                test=\"train\",\n",
    "                image_dataset=False,\n",
    "                worker_init_fn=worker_init_fn,\n",
    "                **kwargs):\n",
    "\n",
    "    ds = APTOSDataset(\n",
    "        root_dir,\n",
    "        df,\n",
    "        test=test,\n",
    "        **kwargs)\n",
    "\n",
    "    drop_last = test == \"test\"\n",
    "    loader = DataLoader(\n",
    "        ds, batch_size=batch_size, shuffle=shuffle,\n",
    "        num_workers=conf.num_workers,\n",
    "        drop_last=drop_last)\n",
    "    return loader, len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 arch_name='resnet18',\n",
    "                 input_channel=3,\n",
    "                 input_size=224,\n",
    "                 num_classes=28):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.base_model = torchvision.models.__dict__[arch_name](pretrained=\"imagenet\")\n",
    "        if isinstance(input_size, tuple):\n",
    "            ksize = (input_size[0] // 16, input_size[1] // 16)\n",
    "        else:\n",
    "            ksize = input_size // 16\n",
    "\n",
    "        self.base_model.bn0 = nn.BatchNorm2d(input_channel)\n",
    "        self.base_model.avgpool = nn.AvgPool2d(kernel_size=ksize)\n",
    "\n",
    "        self.dim_feats = self.base_model.fc.in_features  # = 2048\n",
    "        self.base_model.fc = nn.Linear(self.dim_feats, num_classes)\n",
    "        self.out_size = ksize\n",
    "\n",
    "    def forward(self, data):\n",
    "        # x = self.base_model.bn0(data)\n",
    "        x = self.base_model.conv1(data)\n",
    "        x = self.base_model.bn1(x)\n",
    "        x = self.base_model.relu(x)\n",
    "\n",
    "        x = self.base_model.layer1(x)\n",
    "        x = self.base_model.layer2(x)\n",
    "        x = self.base_model.layer3(x)\n",
    "        x = self.base_model.layer4(x)\n",
    "        x = self.base_model.avgpool(x)\n",
    "        x = x.view(-1, self.dim_feats)\n",
    "        x = self.base_model.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineLR(_LRScheduler):\n",
    "    \"\"\"SGD with cosine annealing.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, step_size_min=1e-5, t0=100, tmult=2, curr_epoch=-1, last_epoch=-1):\n",
    "        self.step_size_min = step_size_min\n",
    "        self.t0 = t0\n",
    "        self.tmult = tmult\n",
    "        self.epochs_since_restart = curr_epoch\n",
    "        super(CosineLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        self.epochs_since_restart += 1\n",
    "\n",
    "        if self.epochs_since_restart > self.t0:\n",
    "            self.t0 *= self.tmult\n",
    "            self.epochs_since_restart = 0\n",
    "\n",
    "        lrs = [self.step_size_min + (\n",
    "                    0.5 * (base_lr - self.step_size_min) * (1 + cos(self.epochs_since_restart * pi / self.t0)))\n",
    "               for base_lr in self.base_lrs]\n",
    "\n",
    "        # print(lrs)\n",
    "\n",
    "        return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://inclass.kaggle.com/gennadylaptev/qwk-loss-for-pytorch/data\n",
    "# Categorical Crossentropyから途中で切り替えるのがいいらしい（https://arxiv.org/pdf/1612.00775.pdf）\n",
    "def kappa_loss(p, y, n_classes=5, eps=1e-10):\n",
    "    \"\"\"\n",
    "    QWK loss function as described in https://arxiv.org/pdf/1612.00775.pdf\n",
    "    \n",
    "    Arguments:\n",
    "        p: a tensor with probability predictions, [batch_size, n_classes],\n",
    "        y, a tensor with one-hot encoded class labels, [batch_size, n_classes]\n",
    "    Returns:\n",
    "        QWK loss\n",
    "    \"\"\"\n",
    "    \n",
    "    W = np.zeros((n_classes, n_classes))\n",
    "    for i in range(n_classes):\n",
    "        for j in range(n_classes):\n",
    "            W[i,j] = (i-j)**2\n",
    "    \n",
    "    W = torch.from_numpy(W.astype(np.float32)).to(conf.device_name)\n",
    "    \n",
    "    p = p.sigmoid()\n",
    "    O = torch.matmul(y.t(), p)\n",
    "    E = torch.matmul(y.sum(dim=0).view(-1,1), p.sum(dim=0).view(1,-1)) / O.sum()\n",
    "    \n",
    "    return (W*O).sum() / ((W*E).sum() + eps)\n",
    "\n",
    "\n",
    "def calc_loss(pred, labels, criterion):\n",
    "    if isinstance(pred, list):\n",
    "        pred_len = len(pred)\n",
    "        pred_probs = 0\n",
    "        clf_loss = 0\n",
    "        for i, px in enumerate(pred):\n",
    "            pred_probs += px.sigmoid().cpu().data.numpy()\n",
    "            clf_loss += criterion(px, labels)\n",
    "        return clf_loss / pred_len, pred_probs / pred_len\n",
    "    else:\n",
    "        pred_probs = pred.sigmoid().cpu().data.numpy()\n",
    "        clf_loss = criterion(pred, labels)\n",
    "        return clf_loss, pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_df,\n",
    "            aug,\n",
    "            device,\n",
    "            data_dir='input/train'):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    dataloader, ds_size = make_loader(\n",
    "        test_df,\n",
    "        data_dir,\n",
    "        conf.batch_size,\n",
    "        shuffle=False,\n",
    "        test=\"test\",\n",
    "        augment=aug)\n",
    "\n",
    "    all_preds = []\n",
    "    # Iterate over data.\n",
    "    t = dataloader\n",
    "    for i, samples in enumerate(t):\n",
    "        with torch.set_grad_enabled(False):\n",
    "            inputs = samples['data'].to(device)\n",
    "            outputs = model(inputs)\n",
    "            all_preds.append(outputs.cpu().data.numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(test_df,\n",
    "                model_path,\n",
    "                criterion,\n",
    "                log,\n",
    "                device):\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(model_path)\n",
    "    test_preds = predict(model, test_df, valid_transform,\n",
    "                         device, data_dir=conf.test_dir)\n",
    "\n",
    "    return test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    exp_name = \"2019_07_13_02_36_49\"\n",
    "    device, log, result_dir = setup(exp_name, conf)\n",
    "    test_df = load_csv(conf.test_csv)\n",
    "    fpath = \"../result/2019_07_13_02_36_49/model_0.pkl\"\n",
    "\n",
    "    test_preds = inference(\n",
    "        test_df,\n",
    "        fpath,\n",
    "        criterion,\n",
    "        log,\n",
    "        device)\n",
    "    \n",
    "    test_df['diagnosis'] = np.argmax(test_preds, axis=1)\n",
    "    test_df.to_csv(f'../pred/{exp_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "configuration is following...\n",
      "{'accum_time': 4,\n",
      " 'alpha': 1,\n",
      " 'batch_size': 16,\n",
      " 'classes_num': 5,\n",
      " 'device_name': 'cuda:0',\n",
      " 'eta_min': 1e-06,\n",
      " 'fold': 0,\n",
      " 'image_size': 256,\n",
      " 'init_lr': 0.001,\n",
      " 'lr_step_epoch': 64,\n",
      " 'n_splits': 5,\n",
      " 'num_epoch': 320,\n",
      " 'num_workers': 16,\n",
      " 'seed': 71,\n",
      " 'test_csv': '../input/sample_submission.csv',\n",
      " 'test_dir': '../input/test',\n",
      " 'train_csv': '../input/train.csv',\n",
      " 'train_dir': '../input/train'}\n",
      "done\n",
      "classification learning start\n",
      "--------------------\n",
      "parameters 23518283\n",
      "Optimizer: Adam\n",
      "Scheduler: CosineAnnealingLR, step_size=64\n",
      "0\t133.39\t135.2\t0.0010\t0.3365\t0.5650369490226512\t0.3232\t0.6703980569127402\t\n",
      "1\t134.51\t269.7\t0.0010\t0.3075\t0.6305859955975965\t0.2630\t0.7635706249325117\t\n",
      "2\t133.55\t403.3\t0.0010\t0.2917\t0.6410851067140959\t0.2435\t0.7405345682133839\t\n",
      "3\t136.87\t540.2\t0.0010\t0.2917\t0.6578330352120282\t0.2362\t0.7894199312714777\t\n",
      "4\t137.21\t677.4\t0.0010\t0.2803\t0.6745074637567295\t0.2471\t0.7467522441589554\t\n",
      "5\t137.36\t814.7\t0.0010\t0.2764\t0.662803880670065\t0.2333\t0.7914488221892731\t\n",
      "6\t134.56\t949.3\t0.0010\t0.2694\t0.7038732293023255\t0.2336\t0.7898133435888094\t\n",
      "7\t134.30\t1083.6\t0.0010\t0.2584\t0.7042446372838217\t0.2205\t0.8106230010601619\t\n",
      "8\t136.47\t1220.1\t0.0010\t0.2605\t0.707328704788907\t0.2145\t0.8329300122949965\t\n",
      "9\t136.61\t1356.7\t0.0009\t0.2536\t0.7202523692122301\t0.2082\t0.8091056477459059\t\n",
      "10\t136.11\t1492.8\t0.0009\t0.2472\t0.724804771539993\t0.2041\t0.8248784790165336\t\n",
      "11\t136.69\t1629.5\t0.0009\t0.2388\t0.7632772254126976\t0.2165\t0.8190522264543567\t\n",
      "12\t135.90\t1765.4\t0.0009\t0.2436\t0.7420635950823671\t0.2164\t0.8192662975785583\t\n",
      "13\t137.01\t1902.4\t0.0009\t0.2428\t0.7643220063045135\t0.2244\t0.8206679527883365\t\n",
      "14\t133.77\t2036.2\t0.0009\t0.2348\t0.7653983536143733\t0.2134\t0.8339501917394755\t\n",
      "15\t135.22\t2171.5\t0.0009\t0.2363\t0.7918684641657436\t0.2220\t0.8150473628081719\t\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
